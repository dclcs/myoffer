## Q1: 进程切换

为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：
1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新PCB信息。
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

## Q2: I/O 

- I/O 模式
  - 刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：
    1. 等待数据准备 (Waiting for the data to be ready)
    2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

    正是因为这两个阶段，linux系统产生了下面五种网络模式的方案。
    - 阻塞 I/O（blocking IO）
      - 在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：
        ![](img/block.png)
      - 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。
      - 所以，blocking IO的特点就是在IO执行的两个阶段都被block了
    - 非阻塞 I/O（nonblocking IO）
      - linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：
        ![](img/noblock.png)
      - 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。
      - 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。
    - I/O 多路复用（ IO multiplexing）
      - IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。
        ![](img/iomulti.png) 
      - 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。

      - 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。

      - 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。

      - 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）

      - 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。


    - 信号驱动 I/O（ signal driven IO）


    - 异步 I/O（asynchronous IO）
      - Linux下的asynchronous IO其实用得很少。先看一下它的流程：
      ![](img/asyio.png)
      - 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

- 总结
  - blocking和non-blocking的区别
    - 调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。

  - synchronous IO和asynchronous IO的区别
    - 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：
      - A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;
      - An asynchronous I/O operation does not cause the requesting process to be blocked;

    - 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。
    - non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据
      





## Q3: EPOLL,SELECT,POLL

select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）

- Select


    `int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);`
    - select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。

    - select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。

- poll

    `int poll (struct pollfd *fds, unsigned int nfds, int timeout);`
    - 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。
    - pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。

- epoll
  - epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

  - 操作过程
  ```c++
  int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
  int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
  ```

1. ` int epoll_create(int size);`

   - 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

2. `int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；`
函数是对指定描述符fd执行op操作。
   - epfd：是epoll_create()的返回值。
   - op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
   - fd：是需要监听的fd（文件描述符）
   - epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：

3. `int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);`

   - 等待epfd上的io事件，最多返回maxevents个事件。
   - 参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。

- Epoll 工作模式
  - epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：
    - LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
        - LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。
    - ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。
      - ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)









## Q4: 进程，线程和协程的区别

- 进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；
- 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。
- 区别：

    1.一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。

    2.进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）

    3.进程是资源分配的最小单位，线程是CPU调度的最小单位；

    4.系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。

    5.通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预

    6.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

    7.进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉

    8.进程适应于多核、多机分布；线程适用于多核


## Q5: 进程间的通信方式
进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

- 管道：
  - 管道主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信
  - 类型：
    - 普通管道PIPE：
      - 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端
      - 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）
      - 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
    -  命名管道FIFO：
       -  FIFO可以在无关的进程之间交换数据
       -  FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
- 系统IPC
  - 消息队列
    - 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

    - 信号量semaphore
      - 信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
      - 1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

      - 2)信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

      - 3)每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

      - 4)支持信号量组。



    - 信号signal
      - 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

    - 共享内存（Shared Memory）
      - 它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等

    - 套接字SOCKET

## Q5 : 线程间的通信方式
- 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
- 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
- 信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

- 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作


## Q6:并行和并发的区别

- 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。
- 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。



## Q7.内存管理

- 名词
  - 内存： 内存又称主存，是CPU能直接寻址的存储空间，它的特点是存取速率快。内存是电脑中主要部件，它是相对于外存来说。
  - 外存：外储存器是指除计算机内存及CPU缓存以外的储存器，此类储存器一般断电后仍然能保存数据。外存需要通过I/O系统与之交换数据，又称为辅助存储器。常见的外储存器有硬盘、软盘、光盘、U盘等
  - 虚存：虚拟存储器
  - 快存（Cache？）： 介于CPU与内存之间，常用有一级缓存（L1）、二级缓存（L2）、三级缓存（L3）（一般存在于Intel系列）。它的读写速度比内存还快，当CPU在内存中读取或写入数据时，数据会被保存在高级缓冲存储器中，当下次访问该数据时，CPU直接读取高级缓冲存储器，而不是更慢的内存。

- 虚拟内存：
  - 在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行时，当访问的信息不在内存时，有操作系统将所需部分调入内存继续执行，且将暂时不用的部分换出到外存。这样系统好像为用户提供了一个比实际内存大得多的存储器， **虚拟存储器**
  - 优点
    - 多次性， 无需在作业运行时一次性的全部装入内存，而是允许分多次调入内存运行
    - 对换性，无需再作业运行时一直常驻内存，而是允许再作业运行过程当中，进行换出和换进
    - 虚拟性，逻辑上扩充了内存的容量
  - 实现
    - 请求分页存储管理
      - 页表的原理#TODO
        - 在分页系统中，允许将进程的各个页离散的存储在内存的任一物理块中。系统为每个进程建立了一张页表。进程地址空间内所有的页面，依次在页面中有一页表项记录了相应的页面对于的物理块号。进程执行时，通过查找页表可以找到每页在内存的物理快好。（页号-> 物理块号的地址映射）
    - 请求分段存储管理
    - 请求段页式存储管理
    - 什么是段页式存储 #TODO
        - 进程的地址空间首先被分为若干个逻辑段，每段由自己的段号，然后再将每一段分成若干大小固定的页。每个进程建立一张段表，每个分段建立一张页表


## Q8: LRU 实现：

- LRU是Least Recently Used的缩写，即最近最少使用，常用于页面置换算法，是为虚拟页式存储管理服务的。

- LRU 算法的设计原则是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰。


```c++
  class DLinkedNode {
      public: 
      int key;
      int val;
      DLinkedNode *pre;
      DLinkedNode *next;
      
      
      DLinkedNode(int _key, int _val): key(_key), val(_val), pre(NULL), next(NULL){}
      DLinkedNode(): key(0), val(0), pre(NULL), next(NULL){}
  };
  
  class LRUCache {
  private:
      unordered_map<int, DLinkedNode *> m;
      int cap;
      int size;
      DLinkedNode *head;
      DLinkedNode *tail;
      
  public:
      LRUCache(int _cap): cap(_cap) {
          size = 0;
          head = new DLinkedNode();
          tail = new DLinkedNode();
          
          head->next = tail;
          tail->pre = head;
      }
      
      int get(int key) {
          if (!m.count(key)) {
              return -1;
          }
          DLinkedNode *node = m[key];  
          moveHead(node);
          return node->val;
      }
      
      void put(int key, int value) {
          if (m.count(key)) {
              DLinkedNode *node = m[key];  
              node->val = value;
              moveHead(node);
              return;
          }
          
          DLinkedNode *node = new DLinkedNode(key, value);
          m[key] = node;
          addHead(node);
          size++;
          if (size > cap) {
              DLinkedNode *t = removeTail();  
              m.erase(t->key);
              size--;
         //     delete t;
          }
      }
      
      void addHead(DLinkedNode *n) {
          DLinkedNode *f = head->next;
          f->pre = n;
          n->next = f;
          n->pre = head;
          head->next = n;
      }
      
      void moveHead(DLinkedNode *node) {
          removeNode(node);
          addHead(node);
      }
      
      DLinkedNode *removeTail() {
          DLinkedNode *d = tail->pre;   
          d->pre->next = tail;
          tail->pre = d->pre;
          return d;
      }
      
      void removeNode(DLinkedNode *node) {
          node->next->pre = node->pre;
          node->pre->next = node->next;
      }
  };
  
  /**
   * Your LRUCache object will be instantiated and called as such:
   * LRUCache* obj = new LRUCache(capacity);
   * int param_1 = obj->get(key);
   * obj->put(key,value);
   */
  ```

## Q9: 孤儿进程、僵尸进程和守护进程

- 孤儿进程
  - 孤儿进程指的是在其父进程执行完成或被终止 后仍继续运行的一类进程。
  - 一般情况下，子进程是由父进程创建，而子进程和父进程的退出是无顺序的，两者之间都不知道谁先退出。正常情况下父进程先结束会调用 wait 或者 waitpid 函数等待子进程完成再退出，而一旦父进程不等待直接退出，则剩下的子进程会被init(pid=1)进程接收，成会孤儿进程。（进程树中除了init都会有父进程）
- 僵尸进程
  - 指完成执行（通过 exit 系统调用，或运行时发生致命错误或收到终止信号所致）但在操作系统的进程表中仍然有一个表项（进程控制块PCB），处于"终止状态 "的进程。
  - 如果子进程先退出了，父进程还未结束并且没有调用 wait 或者 waitpid 函数获取子进程的状态信息，则子进程残留的状态信息（ task_struct 结构和少量资源信息）会变成僵尸进程。
- 守护进程
  - 是指在后台运行，没有控制终端与之相连的进程。它独立于控制终端，通常周期性地执行某种任务 。 守护进程脱离于终端是为了避免进程在执行过程中的信息在任何终端上显示并且进程也不会被任何终端所产生的终端信息所打断 。

## Q10:用过多线程和多进程么

![preview](https://pic3.zhimg.com/v2-add56b22280bb4d4ba61b27fdc4d8bc2_r.jpg)

## Q11: 操作系统中的锁有哪几种？分别是什么适用场景？进程等待互斥锁的挂起是怎么工作的？线程上下文都有哪些资源？
- 所有高级语言锁的实现都依赖操作系统底层的锁实现，操作系统层面上锁的实现机制有自旋锁(spinlock)和mutex两种。
  - 自旋锁
    - 自旋锁是一种非阻塞锁，多个线程尝试获取自旋锁时，没有获取到的线程会持续尝试获取直到获取到为止。
  - mutex
    - mutex是阻塞锁，多个线程尝试获取锁时，没有获取到锁的线程会被操作系统调度为阻塞状态直到锁被释放然后才会被重新唤醒。OS线程调度，线程上下文切换带来的开销是很大的，多线程程序如果有大量的线程切换，最坏情况下性能甚至会比单线程运行的代码效率还要差。mutex锁如果被频繁的获取和释放，代价也可想而知

## Q12: 抢占式和非抢占式调度方法
1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

非抢占式（Nonpreemptive）   让进程运行直到结束或阻塞的调度方式   容易实现   适合专用系统，不适合通用系统   
抢占式（Preemptive）   允许将逻辑上可继续运行的在运行过程暂停的调度方式   可防止单一进程长时间独占CPU   系统开销大（降低途径：硬件实现进程切换，或扩充主存以贮存大部分程序）


## Q13: 线程和进程切换区别
系统中的每个程序都是运行在某个进程的上下文中的。最主要的一个区别在于进程切换涉及虚拟地址空间的切换而线程不会。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是TLB（translation Lookaside Buffer，我们不需要关心这个名字只需要知道TLB本质上就是一个cache，是用来加速页表查找的）。由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。

## Q14 : 死锁

- 在两个或多个并发进程中，如果每个进程持有某种资源而又都等待别的进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁
- 死锁产生的原因主要是：
  1. 系统资源不足
  2. 进程推进顺序非法
- 产生死锁的必要条件：
  - 互斥（mutualexclusion），一个资源每次只能被一个进程使用
  - 不可抢占（nopreemption），进程已获得的资源，在未使用完之前，不能强行剥夺
  - 占有并等待（hold andwait），一个进程因请求资源而阻塞时，对已获得的资源保持不放
  - 环形等待（circularwait），若干进程之间形成一种首尾相接的循环等待资源关系。

- 两个线程两个锁如何实现死锁
  - 线程A 先拿到锁A， 在求拿锁B；线程B先拿到锁B在拿锁A


## Q15: 多进程编程中，不同进程是否可以通过全局变量来通信?
- 对于兄弟的进程或者父子进程中有一方使用了exec族函数(进程的代码、数据全部被替换，实际使用的物理内存也是重新申请的)，进程的代码段、数据段、堆栈段都是独立的，没有任何关系，当然系统会为为他们各自都维护页目录和页表信息(每个进程有自己的页目录和页表)。
- 对于父子进程，假设我们在代码中定义了一个全局变量g_test =1;当使用fork()系统调用时，子进程使用的页目录和页表是复制父进程的，所有此时父子进程共享所有数据(当然fork()的返回值不一样，信号位图也不一样)，所以这个时候父子进程读取全局变量g_test的值以及地址都是一样的，因为g_test是被共享的，g_test这块内存在两个进程的页表中都映射了同一块物理内存。
- 如果之后父子进程中有一方执行了写操作(比如子进程进行g_test++)，子进程在在查找页表时会发现这页内存是共享的(内存引用计数大于1)，这时候就触发了写时复制COW机制，系统会为子进程申请一页新内存，并拷贝父进程g_test所在内存页的数据到子进程新申请的内存中，并更新子进程中页表信息(g_test所对应的线性地址映射到新内存)，然后再执行g_test++操作。

- 此时父子进程访问g_test时，虽然变量名一样，变量的线性地址一样(printf(&g_test))，但是他们的值是不一样的，因为这个时候，父子进程的g_test被映射到了不同的物理内存中。

## Q16: 多线程编程中，不同线程是否可以通过全局变量来通信？
首先对于不同进程的线程而言，他们没有什么关系的(代码段、数据段等都不同)，所以不能通过全局变量来通信。

但是对于同一进程内的线程，他们是可以通过全局变量来通信的。

同一进程内的线程，他们都共享进程的代码段、数据段、BSS段。页目录和页表应该是使用进程的页目录和页表。

## Q17: 共享内存为什么最快？

其他IPC通信方式写入数据需要把数据从进程复制到内核，读取数据的时候又需要把数据从内核复制到进程。所以这种IPC方式往往需要2次在内核和进程之间进行数据的复制，即进程间的通信必需借助内核来传递


共享内存的消息复制只有两次。一是，从输入文件到共享内存；二是，从共享内存到输出文件。这样就很大程度上提高了数据存取的效率。


## Q18: 文件描述符
- 文件描述符（file descriptor）， 是一个非负整数（通常是小整数）用于指代被打开的文件，所有执行I/O操作的系统调用都通过文件描述符。程序刚刚启动的时候，0是标准输入，1是标准输出，2是标准错误。
  - 一个 Linux 进程启动后，会在内核空间中创建一个 PCB 控制块，PCB 内部有一个文件描述符表（File descriptor table），记录着当前进程所有可用的文件描述符，也即当前进程所有打开的文件。
  - 除了文件描述符表，系统还需要维护另外两张表：
    - 打开文件表
    - i-Node 表

![](img/file_des.png)


## Q19: 一个线程卡死为什么会导致整个进程卡死？
- 线程虽然有自己的堆栈和局部变量，但线程没有单独的地址空间，一个线程死掉就等于整个进程死掉

## Q20: malloc 原理
- malloc 函数的实质是它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表。 调用 malloc（）函数时，它沿着连接表寻找一个大到足以满足用户请求所需要的内存块。 然后，将该内存块一分为二（一块的大小与用户申请的大小相等，另一块的大小就是剩下来的字节）。 接下来，将分配给用户的那块内存存储区域传给用户，并将剩下的那块（如果有的话）返回到连接表上。 调用 free 函数时，它将用户释放的内存块连接到空闲链表上。 到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段， 那么空闲链表上可能没有可以满足用户要求的片段了。于是，malloc（）函数请求延时，并开始在空闲链表上检查各内存片段，对它们进行内存整理，将相邻的小空闲块合并成较大的内存块。
- 现在考虑如何在block链中查找合适的block。一般来说有两种查找算法：

  - First fit：从头开始，使用第一个数据区大小大于要求size的块所谓此次分配的块
  - Best fit：从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块


## Q13：消费者和生产者的问题

## Q14: 进程通信方式，socket和其余几种的区别


## Q15: 线程安全?如何保证线程安全?多线程的同步?


- 虚拟内存，常驻内存和共享内存区别
- 内存缺页中断
- fork
- 同步和异步
- 
- 父进程占4G存储空间，那么fork的子进程占多少？
- 原子操作是什么
- 死锁


pthread相关函数
• locker,sem相关函数
• 如何结束线程
• 长耗时任务如何进行多线程或多进程优化